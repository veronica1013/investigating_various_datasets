# 1.0 Investigating Various Datasets
This repository entails data investigation/wrangling. The tasks include:
##### Step 1: Gathering data
##### Step 2: Assessing data
##### Step 3: Cleaning data
##### Step 4: Storing data
##### Step 5: Analyzing, and visualizing data
##### Step 6: Reporting

The various data sets are as listed below:
### 1.1 No Show Appointment Data
> Dataset Details:The dataset for this project was obtained from [kaggle website](https://www.kaggle.com/datasets/joniarroba/noshowappointments) and the link to the dataset is available [here](https://d17h27t6h515a5.cloudfront.net/topher/2017/October/59dd2e9a_noshowappointments-kagglev2-may-2016/noshowappointments-kagglev2-may-2016.csv). More information about the dataset is also found [here](https://docs.google.com/document/d/e/2PACX-1vTlVmknRRnfy_4eTrjw5hYGaiQim5ctr9naaRd4V9du2B5bxpd8FEH3KtDgp8qVekw7Cj1GLk1IXdZi/pub).

### 1.2 [We Rate Dogs Dataset](https://en.wikipedia.org/wiki/WeRateDogs)
> Dataset Details: 
* a. The first data set, ```twitter_archive_enhanced```, was obtained from this [link](https://help.twitter.com/en/managing-your-account/how-to-download-your-twitter-archive)
* b. The second dataset which is ```tweet_image_predictions``` named as ```image_predictions.tsv``` is present in each tweet according to a neural network. It should be downloaded programmatically using the ```requests``` library and this [URL](https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv).
* c. The third data should be obtained by querying Twitter's API using ```tweepy``` for additional data beyond the data included in the WeRateDogs Twitter archive


## 2.0 Software Used
* pandas
* NumPy
* requests
* tweepy
* json
